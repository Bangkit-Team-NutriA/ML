{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EfficientNet.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bKuoRyUU2pNd",
        "outputId": "b6b37e1f-943b-4829-f866-7caedd460551"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"/content/drive/MyDrive/datasetFoodImage/images.zip\" -d \"/content/sample_data/data\""
      ],
      "metadata": {
        "id": "SF_JnrL53UYo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from google.colab import files\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, BatchNormalization\n",
        "from tensorflow.keras import Sequential, Input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, Callback\n",
        "from tensorflow_hub import KerasLayer\n",
        "from tensorflow.keras.metrics import Precision,Recall\n",
        "import math"
      ],
      "metadata": {
        "id": "gzaGkt1b332l"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EfficientV2LPath = 'https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet21k_ft1k_l/feature_vector/2'"
      ],
      "metadata": {
        "id": "wXZh3aeNKbDk"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelCNN = KerasLayer(EfficientV2LPath , trainable = False, input_shape = (250,250,3), name = 'EfficientNet')"
      ],
      "metadata": {
        "id": "V28gZxdvyAJD"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(modelCNN):\n",
        "  model = Sequential([\n",
        "    Input(shape=(250,250,3)),\n",
        "    modelCNN,   \n",
        "    Dense(108, activation=\"softmax\")\n",
        "  ])\n",
        "  model.compile(optimizer='Adam', loss=\"categorical_crossentropy\", metrics=[\"accuracy\", Precision(), Recall()])\n",
        "  return model"
      ],
      "metadata": {
        "id": "vxciHaP0c601"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_model(modelCNN)"
      ],
      "metadata": {
        "id": "ErA5XE0Scktq"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43NhXqucfWW5",
        "outputId": "3efea205-435c-4da8-edd0-3832cada8939"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " EfficientNet (KerasLayer)   (None, 1280)              117746848 \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 108)               138348    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 117,885,196\n",
            "Trainable params: 138,348\n",
            "Non-trainable params: 117,746,848\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datagen = ImageDataGenerator(\n",
        "    rescale = 1./255,\n",
        "    validation_split=0.1)"
      ],
      "metadata": {
        "id": "V2SJQ1_v5tpi"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_generator = datagen.flow_from_directory(\n",
        "    \"/content/sample_data/data/images\",\n",
        "    target_size=(250,250),\n",
        "    subset='training'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fphjtup950-z",
        "outputId": "2aa735c6-9dcc-4cab-9fea-6e0a30444750"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 91064 images belonging to 108 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "valid_data_generator = datagen.flow_from_directory(\n",
        "    \"/content/sample_data/data/images\",\n",
        "    target_size=(250,250),\n",
        "    subset='validation'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ekdxGZJf5-vD",
        "outputId": "d2fbdb65-cce3-4066-d664-5cb0a015ab11"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 10115 images belonging to 108 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "freq = 91064/32"
      ],
      "metadata": {
        "id": "h-3UeQLOfon_"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = ModelCheckpoint(\"/content/sample_data/model/Effnet_{epoch:02d}_{accuracy:.2f}.h5\", verbose=1, mode='auto', save_freq=2846)"
      ],
      "metadata": {
        "id": "N00RWm-1bJ9S"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class myCallback(Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    path = '/content/sample_data/trainingHistoryEfficientNet.json'\n",
        "    with open(path) as f:\n",
        "      data = json.load(f)\n",
        "    os.remove(path)\n",
        "    dictLogs = {\n",
        "        'loss': logs.get('loss'),\n",
        "        'accuracy': logs.get('accuracy'),\n",
        "        'val_loss': logs.get('val_loss'),\n",
        "        'val_accuracy': logs.get('val_accuracy'),\n",
        "        'val_precision': logs.get('val_precision_4'),\n",
        "        'val_recall': logs.get('val_recall_4'),\n",
        "        'recall': logs.get('recall_4'),\n",
        "        'precision': logs.get('precision_4')\n",
        "    }\n",
        "    data.append(dictLogs)\n",
        "    json_object = json.dumps(data, indent = 4)\n",
        "    with open(path, \"w\") as outJson:\n",
        "      outJson.write(json_object)"
      ],
      "metadata": {
        "id": "pbltyg8eikAi"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = myCallback()"
      ],
      "metadata": {
        "id": "IIcJ2NgHlXgm"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_data_generator, validation_data=valid_data_generator, epochs=5,callbacks=[checkpoint, callbacks])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MN3Iw25iqNVo",
        "outputId": "e2ac6944-87b5-4294-e377-3821d659f71d"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "2845/2846 [============================>.] - ETA: 1s - loss: 1.0524 - accuracy: 0.7335 - precision_4: 0.8811 - recall_4: 0.6279\n",
            "Epoch 1: saving model to /content/sample_data/model/Effnet_01_0.73.h5\n",
            "2846/2846 [==============================] - 3265s 1s/step - loss: 1.0522 - accuracy: 0.7336 - precision_4: 0.8812 - recall_4: 0.6280 - val_loss: 0.8125 - val_accuracy: 0.7901 - val_precision_4: 0.8805 - val_recall_4: 0.7339\n",
            "Epoch 2/5\n",
            "2845/2846 [============================>.] - ETA: 1s - loss: 0.6504 - accuracy: 0.8230 - precision_4: 0.9003 - recall_4: 0.7679\n",
            "Epoch 2: saving model to /content/sample_data/model/Effnet_02_0.82.h5\n",
            "2846/2846 [==============================] - 3279s 1s/step - loss: 0.6505 - accuracy: 0.8230 - precision_4: 0.9003 - recall_4: 0.7679 - val_loss: 0.8170 - val_accuracy: 0.7914 - val_precision_4: 0.8675 - val_recall_4: 0.7462\n",
            "Epoch 3/5\n",
            "2845/2846 [============================>.] - ETA: 1s - loss: 0.5318 - accuracy: 0.8530 - precision_4: 0.9161 - recall_4: 0.8059\n",
            "Epoch 3: saving model to /content/sample_data/model/Effnet_03_0.85.h5\n",
            "2846/2846 [==============================] - 3290s 1s/step - loss: 0.5318 - accuracy: 0.8530 - precision_4: 0.9161 - recall_4: 0.8059 - val_loss: 0.8342 - val_accuracy: 0.7917 - val_precision_4: 0.8603 - val_recall_4: 0.7530\n",
            "Epoch 4/5\n",
            "2845/2846 [============================>.] - ETA: 1s - loss: 0.4571 - accuracy: 0.8714 - precision_4: 0.9250 - recall_4: 0.8296\n",
            "Epoch 4: saving model to /content/sample_data/model/Effnet_04_0.87.h5\n",
            "2846/2846 [==============================] - 3294s 1s/step - loss: 0.4571 - accuracy: 0.8714 - precision_4: 0.9250 - recall_4: 0.8296 - val_loss: 0.8742 - val_accuracy: 0.7925 - val_precision_4: 0.8508 - val_recall_4: 0.7597\n",
            "Epoch 5/5\n",
            "2845/2846 [============================>.] - ETA: 1s - loss: 0.4023 - accuracy: 0.8859 - precision_4: 0.9330 - recall_4: 0.8483\n",
            "Epoch 5: saving model to /content/sample_data/model/Effnet_05_0.89.h5\n",
            "2846/2846 [==============================] - 3275s 1s/step - loss: 0.4022 - accuracy: 0.8859 - precision_4: 0.9331 - recall_4: 0.8484 - val_loss: 0.9015 - val_accuracy: 0.7870 - val_precision_4: 0.8473 - val_recall_4: 0.7566\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f66b3e976d0>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    }
  ]
}